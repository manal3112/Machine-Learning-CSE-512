{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import scipy.stats as ss\n",
    "\n",
    "import sklearn.model_selection as ms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata = []\\nf = open('covtype.data','r')\\nwhile(1):\\n    line = f.readline()\\n    if  len(line) < 100:\\n        print line\\n    \\n    if len(line) == 0: break\\n    data.append(np.array([float(k) for k in line.split(',')]))\\n    if len(data) % 100000 == 0:\\n        print len(data)\\n        \\nf.close\\ndata = np.vstack(data)\\nN = data.shape[0]\\nidx = np.random.permutation(N)\\n\\n\\nX_test = data[:N/5,:]\\nX_train = data[N/5:,:]\\ny_test = X_test[:,-1]\\ny_train = X_train[:,-1]\\nX_test = X_test[:,:-1]\\nX_train = X_train[:,:-1]\\n\\n\\nsio.savemat('covtype.mat',{'X_train':X_train,'X_test':X_test,'y_train':y_train,'y_test':y_test})\\n\\ndata = sio.loadmat('covtype.mat')\\nX_train = data['X_train']\\nX_test = data['X_test']\\ny_train = data['y_train'][0]\\ny_test = data['y_test'][0]\\n\\ny_idx_train = [np.where(np.equal(y_train,k))[0] for k in np.unique(y_train)]\\n\\nfor i in xrange(len(y_idx_train)):\\n    y_idx = y_idx_train[i]\\n    y_idx_train[i] = y_idx[np.random.choice(len(y_idx),len(y_idx)/1000+1,replace=False)]\\n    \\ny_idx_train = np.hstack(y_idx_train)\\ny_idx_train = np.random.permutation(y_idx_train)\\n\\nX_train = X_train[y_idx_train,:]\\ny_train = y_train[y_idx_train]\\n\\nsio.savemat('covtype_reduced.mat',{'X_train':X_train,'X_test':X_test,'y_train':y_train,'y_test':y_test})\\n\\n\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load your data (don't touch, just run)\n",
    "\"\"\"\n",
    "data = []\n",
    "f = open('covtype.data','r')\n",
    "while(1):\n",
    "    line = f.readline()\n",
    "    if  len(line) < 100:\n",
    "        print line\n",
    "    \n",
    "    if len(line) == 0: break\n",
    "    data.append(np.array([float(k) for k in line.split(',')]))\n",
    "    if len(data) % 100000 == 0:\n",
    "        print len(data)\n",
    "        \n",
    "f.close\n",
    "data = np.vstack(data)\n",
    "N = data.shape[0]\n",
    "idx = np.random.permutation(N)\n",
    "\n",
    "\n",
    "X_test = data[:N/5,:]\n",
    "X_train = data[N/5:,:]\n",
    "y_test = X_test[:,-1]\n",
    "y_train = X_train[:,-1]\n",
    "X_test = X_test[:,:-1]\n",
    "X_train = X_train[:,:-1]\n",
    "\n",
    "\n",
    "sio.savemat('covtype.mat',{'X_train':X_train,'X_test':X_test,'y_train':y_train,'y_test':y_test})\n",
    "\n",
    "data = sio.loadmat('covtype.mat')\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train'][0]\n",
    "y_test = data['y_test'][0]\n",
    "\n",
    "y_idx_train = [np.where(np.equal(y_train,k))[0] for k in np.unique(y_train)]\n",
    "\n",
    "for i in xrange(len(y_idx_train)):\n",
    "    y_idx = y_idx_train[i]\n",
    "    y_idx_train[i] = y_idx[np.random.choice(len(y_idx),len(y_idx)/1000+1,replace=False)]\n",
    "    \n",
    "y_idx_train = np.hstack(y_idx_train)\n",
    "y_idx_train = np.random.permutation(y_idx_train)\n",
    "\n",
    "X_train = X_train[y_idx_train,:]\n",
    "y_train = y_train[y_idx_train]\n",
    "\n",
    "sio.savemat('covtype_reduced.mat',{'X_train':X_train,'X_test':X_test,'y_train':y_train,'y_test':y_test})\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3. 4. 5. 6. 7.] [1. 2. 3. 4. 5. 6. 7.]\n",
      "(468, 54) (116202, 54) (468,) (116202,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = sio.loadmat('covtype_reduced.mat')\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train'][0]\n",
    "y_test = data['y_test'][0]\n",
    "\n",
    "print (np.unique(y_train), np.unique(y_test))\n",
    "\n",
    "print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy =  3.314182323161083\n",
      "conditional entropy =  3.3029598816135177\n"
     ]
    }
   ],
   "source": [
    "def entropy(label):\n",
    "    \n",
    "    entropy = 0\n",
    "    _, counts = np.unique(label, return_counts = True)\n",
    "    \n",
    "    for count in counts:\n",
    "        prob_i = count/label.shape[0]\n",
    "        entropy += - (prob_i * np.log2(prob_i)) if count != 0 else 0 #Assuming 0log2(0) = 0\n",
    "        \n",
    "    return entropy\n",
    "\n",
    "def cond_entropy(label,split):\n",
    "    \n",
    "    cond_entropy = 0\n",
    "    splits, counts = np.unique(split, return_counts = True)\n",
    "    \n",
    "    for i, count in enumerate(counts):\n",
    "        cond_entropy += count/split.shape[0] * entropy(label[split == splits[i]])\n",
    "    \n",
    "    return cond_entropy\n",
    "\n",
    "random_sequences = sio.loadmat('random_sequences.mat')\n",
    "\n",
    "s1 = random_sequences['s1'][0]\n",
    "s2 = random_sequences['s2'][0]\n",
    "\n",
    "print ('entropy = ', entropy(s1))\n",
    "print ('conditional entropy = ', cond_entropy(s1,s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "information gained in first step 0.3426560413513844\n"
     ]
    }
   ],
   "source": [
    "def find_best_split(x,y):\n",
    "    best_feat = 0\n",
    "    splitval = 0.\n",
    "    ig_max = -np.inf\n",
    "    entropyval = entropy(y)\n",
    "    feature_idx = x.shape[1]\n",
    "    #print(x.shape)\n",
    "    for feature in range(feature_idx):                                                           \n",
    "        for curr_splitval in sorted(np.unique(x[:, feature]))[1:]: #feature's smallest value has zero entropy\n",
    "            y_split = y * 0\n",
    "            #print(y_split.shape)\n",
    "            y_split[x[:, feature] < curr_splitval] = 1 \n",
    "            curr_ig_max = entropyval - cond_entropy(y, y_split)\n",
    "\n",
    "            if curr_ig_max > ig_max:\n",
    "                ig_max    = curr_ig_max\n",
    "                best_feat = feature\n",
    "                splitval  = curr_splitval\n",
    "                \n",
    "    left_cond = np.less(x[:, best_feat], splitval)\n",
    "    right_cond = ~left_cond #np.greater_equal(x[:, best_feat], splitval)\n",
    "    \n",
    "    set1 = np.transpose(np.nonzero(left_cond)).reshape(-1,)\n",
    "    set2 = np.transpose(np.nonzero(right_cond)).reshape(-1,)\n",
    "    \n",
    "    return best_feat, splitval, set1, set2\n",
    "\n",
    "best_feat, splitval, set1, set2 = find_best_split(X_train, y_train)\n",
    "y_new = y_train * 0\n",
    "y_new[set1] = 1\n",
    "print ('information gained in first step', entropy(y_train) - cond_entropy(y_train,y_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity(y):\n",
    "    return ss.mode(y)[1]/len(y+0.)\n",
    "    \n",
    "class Node:\n",
    "    def __init__(self,  sample_idx, nodeid,  is_leaf = True):\n",
    "        self.is_leaf = is_leaf\n",
    "        self.id = nodeid\n",
    "        self.sample_idx = sample_idx\n",
    "        self.children = []\n",
    "        \n",
    "    def visit_node(self, x):\n",
    "        if self.is_leaf:\n",
    "            return self.label\n",
    "        elif x[self.splitfeat] < self.splitval:\n",
    "            return self.children[1].visit_node(x)\n",
    "        return self.children[0].visit_node(x)\n",
    "        \n",
    "    def add_split_details(self, splitfeat, splitval)  :\n",
    "        self.splitfeat = splitfeat\n",
    "        self.splitval = splitval\n",
    "    \n",
    "        \n",
    "class Tree:\n",
    "    def __init__(self, x,y):\n",
    "        m = len(y)\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.maxid = -1\n",
    "        self.root = self.construct_node(np.array(range(m)))\n",
    "        self.leaves = [self.root]\n",
    "        \n",
    "    def print_tree(self):\n",
    "        print ('printing tree...')\n",
    "        def print_node(parent, node):\n",
    "            print (node.id, )\n",
    "            \n",
    "            if parent is not None:\n",
    "                print (', parent ', parent.id,)\n",
    "            else:\n",
    "                print (', ROOT',) \n",
    "                \n",
    "            print (', label ', node.label, )\n",
    "            if node.is_leaf: \n",
    "                print (', LEAF, ', 'nsamples %d, purity %.2f' %(len(node.sample_idx), purity(self.y[node.sample_idx])))\n",
    "            else:\n",
    "                print (', NONLEAF, split %d, val %.2f' % (node.splitfeat, node.splitval))\n",
    "            if not node.is_leaf:\n",
    "                for ch in node.children:\n",
    "                    print_node(node, ch)\n",
    "        print_node(None, self.root)\n",
    "        \n",
    "    def construct_node(self, sample_idx):\n",
    "        node = Node(sample_idx, self.maxid + 1,  True)\n",
    "        \n",
    "        node.label = ss.mode(self.y[sample_idx])[0].item()\n",
    "        \n",
    "        node.entropy = entropy(self.y[sample_idx])\n",
    "        node.num_mistakes = np.sum(np.not_equal(node.label, self.y[sample_idx]))\n",
    "        self.maxid += 1\n",
    "        return node\n",
    "        \n",
    "    def report_train_err(self):\n",
    "        total_mistakes = 0\n",
    "        for leaf in self.leaves:\n",
    "            total_mistakes += leaf.num_mistakes\n",
    "        return total_mistakes / (len(self.y)+0.)\n",
    "        \n",
    "    def predict(self,x):\n",
    "        return self.root.visit_node(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing tree...\n",
      "0\n",
      ", ROOT\n",
      ", label  2.0\n",
      ", LEAF,  nsamples 468, purity 0.44\n",
      "current train err: 0.5641025641025641\n",
      "current test err: 0.3138069912738163\n",
      "printing tree...\n",
      "0\n",
      ", ROOT\n",
      ", label  2.0\n",
      ", NONLEAF, split 0, val 2844.00\n",
      "1\n",
      ", parent  0\n",
      ", label  2.0\n",
      ", LEAF,  nsamples 116, purity 0.46\n",
      "2\n",
      ", parent  0\n",
      ", label  1.0\n",
      ", LEAF,  nsamples 352, purity 0.51\n",
      "one step train err: 0.5021367521367521\n",
      "one step test err: 0.6024336930517546\n"
     ]
    }
   ],
   "source": [
    "def get_test_err(tree):\n",
    "    # get test error\n",
    "    num_test_mistakes = 0\n",
    "    for k in range(len(y_test)):\n",
    "        x,y = X_test[k,:],y_test[k]\n",
    "        if y != tree.predict(x):\n",
    "            num_test_mistakes += 1\n",
    "    return num_test_mistakes / (len(y_test)+0.)\n",
    "\n",
    "tree = Tree(X_train,y_train)\n",
    "tree.print_tree()\n",
    "print ('current train err:', tree.report_train_err())\n",
    "print ('current test err:', get_test_err(tree))\n",
    "\n",
    "# my first split\n",
    "best_feat, splitval, set1, set2 = find_best_split(X_train, y_train)\n",
    " \n",
    "left_child = tree.construct_node(set1)\n",
    "right_child = tree.construct_node(set2)\n",
    "tree.root.is_leaf = False\n",
    "tree.leaves.pop(tree.leaves.index(tree.root))\n",
    "tree.root.add_split_details(splitfeat = best_feat, splitval = splitval)\n",
    "\n",
    "tree.root.children = [left_child, right_child]\n",
    "tree.leaves.extend(tree.root.children)\n",
    "tree.print_tree()\n",
    "print ('one step train err:', tree.report_train_err())\n",
    "print ('one step test err:', get_test_err(tree))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_worst_leaf(leaves):\n",
    "    return sorted([(leaf, purity(tree.y[leaf.sample_idx]).item()) \n",
    "                    for leaf in leaves], key=lambda x: (x[1]))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1.0, Test error: 0.6024336930517546, Train error: 0.5021367521367521\n",
      "Step: 2.0, Test error: 0.6024336930517546, Train error: 0.49145299145299143\n",
      "Step: 3.0, Test error: 0.6024336930517546, Train error: 0.4829059829059829\n",
      "Step: 4.0, Test error: 0.6024336930517546, Train error: 0.47649572649572647\n",
      "Step: 5.0, Test error: 0.3138069912738163, Train error: 0.5341880341880342\n",
      "Step: 6.0, Test error: 0.3138069912738163, Train error: 0.5149572649572649\n",
      "Step: 7.0, Test error: 0.6024336930517546, Train error: 0.5170940170940171\n",
      "Step: 8.0, Test error: 0.6024336930517546, Train error: 0.5042735042735043\n",
      "Step: 9.0, Test error: 0.6024336930517546, Train error: 0.4935897435897436\n",
      "Step: 10.0, Test error: 0.6024336930517546, Train error: 0.4807692307692308\n",
      "Step: 11.0, Test error: 0.6024336930517546, Train error: 0.4658119658119658\n",
      "Step: 12.0, Test error: 0.6024336930517546, Train error: 0.4594017094017094\n",
      "Step: 13.0, Test error: 0.6024336930517546, Train error: 0.45726495726495725\n",
      "Step: 14.0, Test error: 0.6024336930517546, Train error: 0.44871794871794873\n",
      "Step: 15.0, Test error: 0.7846250494827972, Train error: 0.45085470085470086\n",
      "Step: 16.0, Test error: 0.7846250494827972, Train error: 0.44871794871794873\n",
      "Step: 17.0, Test error: 0.7846250494827972, Train error: 0.44871794871794873\n",
      "Step: 18.0, Test error: 0.7940396895062047, Train error: 0.4465811965811966\n",
      "Step: 19.0, Test error: 0.7940396895062047, Train error: 0.4444444444444444\n",
      "Step: 20.0, Test error: 0.8062683946920018, Train error: 0.4423076923076923\n",
      "Step: 21.0, Test error: 0.8062683946920018, Train error: 0.44017094017094016\n",
      "Step: 22.0, Test error: 0.8062683946920018, Train error: 0.4337606837606838\n",
      "Step: 23.0, Test error: 0.8062683946920018, Train error: 0.4337606837606838\n",
      "Step: 24.0, Test error: 0.8062683946920018, Train error: 0.4337606837606838\n",
      "Step: 25.0, Test error: 0.8062683946920018, Train error: 0.43162393162393164\n",
      "Training Error after 25 steps: 0.42948717948717946\n",
      "Test Error after 25 Steps: 0.8062683946920018\n"
     ]
    }
   ],
   "source": [
    "while (tree.maxid <= 51):\n",
    "    \n",
    "    curr_node = pick_worst_leaf(tree.leaves)\n",
    "    \n",
    "    print(\"Step: {}, Test error: {}, Train error: {}\".format(tree.maxid/2, \n",
    "                                                             get_test_err(tree), \n",
    "                                                             tree.report_train_err()))\n",
    "\n",
    "    best_feat, splitval, set1, set2 = find_best_split(X_train[curr_node.sample_idx], \n",
    "                                                      y_train[curr_node.sample_idx])\n",
    "\n",
    "    left_child = tree.construct_node(np.array(set1))\n",
    "    right_child = tree.construct_node(np.array(set2))\n",
    "    curr_node.is_leaf = False\n",
    "    tree.leaves.pop(tree.leaves.index(curr_node))\n",
    "    curr_node.add_split_details(splitfeat = best_feat, splitval = splitval)\n",
    "    \n",
    "    curr_node.children = [left_child, right_child]\n",
    "    tree.leaves.extend(curr_node.children)\n",
    "\n",
    "print ('Training Error after 25 steps:', tree.report_train_err())\n",
    "print ('Test Error after 25 Steps:', get_test_err(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing tree...\n",
      "0\n",
      ", ROOT\n",
      ", label  2.0\n",
      ", NONLEAF, split 0, val 2844.00\n",
      "1\n",
      ", parent  0\n",
      ", label  2.0\n",
      ", NONLEAF, split 0, val 2525.00\n",
      "3\n",
      ", parent  1\n",
      ", label  2.0\n",
      ", NONLEAF, split 9, val 757.00\n",
      "29\n",
      ", parent  3\n",
      ", label  1.0\n",
      ", NONLEAF, split 1, val 299.00\n",
      "31\n",
      ", parent  29\n",
      ", label  1.0\n",
      ", NONLEAF, split 0, val 2739.00\n",
      "33\n",
      ", parent  31\n",
      ", label  1.0\n",
      ", NONLEAF, split 0, val 3131.00\n",
      "35\n",
      ", parent  33\n",
      ", label  3.0\n",
      ", LEAF,  nsamples 1, purity 1.00\n",
      "36\n",
      ", parent  33\n",
      ", label  1.0\n",
      ", NONLEAF, split 0, val 3172.00\n",
      "39\n",
      ", parent  36\n",
      ", label  3.0\n",
      ", LEAF,  nsamples 1, purity 1.00\n",
      "40\n",
      ", parent  36\n",
      ", label  5.0\n",
      ", LEAF,  nsamples 1, purity 1.00\n",
      "34\n",
      ", parent  31\n",
      ", label  1.0\n",
      ", NONLEAF, split 0, val 2739.00\n",
      "37\n",
      ", parent  34\n",
      ", label  5.0\n",
      ", LEAF,  nsamples 1, purity 1.00\n",
      "38\n",
      ", parent  34\n",
      ", label  1.0\n",
      ", NONLEAF, split 0, val 3172.00\n",
      "41\n",
      ", parent  38\n",
      ", label  3.0\n",
      ", LEAF,  nsamples 1, purity 1.00\n",
      "42\n",
      ", parent  38\n",
      ", label  5.0\n",
      ", LEAF,  nsamples 1, purity 1.00\n",
      "32\n",
      ", parent  29\n",
      ", label  1.0\n",
      ", LEAF,  nsamples 3, purity 0.67\n",
      "30\n",
      ", parent  3\n",
      ", label  1.0\n",
      ", LEAF,  nsamples 28, purity 0.54\n",
      "4\n",
      ", parent  1\n",
      ", label  1.0\n",
      ", NONLEAF, split 0, val 2942.00\n",
      "5\n",
      ", parent  4\n",
      ", label  2.0\n",
      ", NONLEAF, split 3, val 331.00\n",
      "7\n",
      ", parent  5\n",
      ", label  1.0\n",
      ", LEAF,  nsamples 10, purity 0.60\n",
      "8\n",
      ", parent  5\n",
      ", label  1.0\n",
      ", LEAF,  nsamples 11, purity 0.64\n",
      "6\n",
      ", parent  4\n",
      ", label  1.0\n",
      ", LEAF,  nsamples 58, purity 0.57\n",
      "2\n",
      ", parent  0\n",
      ", label  1.0\n",
      ", NONLEAF, split 0, val 3171.00\n",
      "9\n",
      ", parent  2\n",
      ", label  1.0\n",
      ", NONLEAF, split 0, val 2886.00\n",
      "11\n",
      ", parent  9\n",
      ", label  1.0\n",
      ", NONLEAF, split 0, val 2783.00\n",
      "27\n",
      ", parent  11\n",
      ", label  1.0\n",
      ", LEAF,  nsamples 6, purity 0.67\n",
      "28\n",
      ", parent  11\n",
      ", label  1.0\n",
      ", LEAF,  nsamples 47, purity 0.57\n",
      "12\n",
      ", parent  9\n",
      ", label  2.0\n",
      ", NONLEAF, split 0, val 2965.00\n",
      "19\n",
      ", parent  12\n",
      ", label  2.0\n",
      ", LEAF,  nsamples 66, purity 0.53\n",
      "20\n",
      ", parent  12\n",
      ", label  1.0\n",
      ", NONLEAF, split 0, val 2886.00\n",
      "21\n",
      ", parent  20\n",
      ", label  2.0\n",
      ", LEAF,  nsamples 22, purity 0.59\n",
      "22\n",
      ", parent  20\n",
      ", label  1.0\n",
      ", LEAF,  nsamples 79, purity 0.52\n",
      "10\n",
      ", parent  2\n",
      ", label  2.0\n",
      ", NONLEAF, split 0, val 3054.00\n",
      "13\n",
      ", parent  10\n",
      ", label  2.0\n",
      ", NONLEAF, split 0, val 2942.00\n",
      "17\n",
      ", parent  13\n",
      ", label  1.0\n",
      ", NONLEAF, split 9, val 895.00\n",
      "23\n",
      ", parent  17\n",
      ", label  1.0\n",
      ", NONLEAF, split 0, val 3200.00\n",
      "25\n",
      ", parent  23\n",
      ", label  3.0\n",
      ", LEAF,  nsamples 1, purity 1.00\n",
      "26\n",
      ", parent  23\n",
      ", label  5.0\n",
      ", LEAF,  nsamples 1, purity 1.00\n",
      "24\n",
      ", parent  17\n",
      ", label  1.0\n",
      ", LEAF,  nsamples 15, purity 0.67\n",
      "18\n",
      ", parent  13\n",
      ", label  1.0\n",
      ", LEAF,  nsamples 46, purity 0.54\n",
      "14\n",
      ", parent  10\n",
      ", label  1.0\n",
      ", NONLEAF, split 0, val 2694.00\n",
      "15\n",
      ", parent  14\n",
      ", label  1.0\n",
      ", LEAF,  nsamples 11, purity 0.55\n",
      "16\n",
      ", parent  14\n",
      ", label  1.0\n",
      ", NONLEAF, split 0, val 2694.00\n",
      "43\n",
      ", parent  16\n",
      ", label  1.0\n",
      ", NONLEAF, split 0, val 3143.00\n",
      "45\n",
      ", parent  43\n",
      ", label  1.0\n",
      ", NONLEAF, split 0, val 3131.00\n",
      "47\n",
      ", parent  45\n",
      ", label  2.0\n",
      ", NONLEAF, split 0, val 3131.00\n",
      "51\n",
      ", parent  47\n",
      ", label  3.0\n",
      ", LEAF,  nsamples 1, purity 1.00\n",
      "52\n",
      ", parent  47\n",
      ", label  5.0\n",
      ", LEAF,  nsamples 1, purity 1.00\n",
      "48\n",
      ", parent  45\n",
      ", label  1.0\n",
      ", NONLEAF, split 0, val 2739.00\n",
      "49\n",
      ", parent  48\n",
      ", label  1.0\n",
      ", LEAF,  nsamples 1, purity 1.00\n",
      "50\n",
      ", parent  48\n",
      ", label  3.0\n",
      ", LEAF,  nsamples 2, purity 0.50\n",
      "46\n",
      ", parent  43\n",
      ", label  1.0\n",
      ", LEAF,  nsamples 5, purity 0.60\n",
      "44\n",
      ", parent  16\n",
      ", label  1.0\n",
      ", LEAF,  nsamples 48, purity 0.58\n"
     ]
    }
   ],
   "source": [
    "tree.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 52\n",
      "Leaves: 27\n"
     ]
    }
   ],
   "source": [
    "print(\"Nodes:\", tree.maxid)\n",
    "print(\"Leaves:\", len(tree.leaves))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, Tree has overfitted. \n",
    "Here we have a relatively smaller training error(42.94%) but very large validation error(80.62%). We see that training error is always going down but validation error is going up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
